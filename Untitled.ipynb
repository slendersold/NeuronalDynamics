{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d32d2b6f-b0ac-436e-8a45-497f98da0f48",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "815700dc-7a18-482a-bff4-3cad206f8c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import subprocess\n",
    "\n",
    "subprocess.run([\"pip\", \"freeze\"], check=True)\n",
    "clear_output(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76d94c40-a2d4-446b-8932-85bd76200ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "import models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from fpdf import FPDF\n",
    "import random\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from omegaconf import OmegaConf\n",
    "import pyedflib\n",
    "from scipy import signal, stats\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c35771d-0bae-4552-9901-9e771cd25e98",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d7753d2-f83b-4d97-8c62-4f2cd9e5d377",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Функции ===\n",
    "def edf_extractor(file_name):\n",
    "    f = pyedflib.EdfReader(file_name)\n",
    "    n = f.signals_in_file\n",
    "    signal_labels = f.getSignalLabels()\n",
    "    sigbufs = np.zeros((n, f.getNSamples()[0]))\n",
    "    for i in np.arange(n):\n",
    "        sigbufs[i, :] = f.readSignal(i)\n",
    "    return sigbufs, signal_labels\n",
    "\n",
    "\n",
    "def plot_time_series(wav, smpl_rate):\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.ylabel(\"Voltage (\\u03bcV)\", fontsize=25)\n",
    "    plt.xticks(\n",
    "        np.arange(0, len(wav) + 1, smpl_rate),\n",
    "        [x / smpl_rate for x in np.arange(0, len(wav) + 1, smpl_rate)],\n",
    "    )\n",
    "    plt.xlabel(\"Time (s)\", fontsize=25)\n",
    "    plt.plot(wav)\n",
    "\n",
    "\n",
    "def get_stft(x, fs, clip_fs=-1, normalizing=None, **kwargs):\n",
    "    f, t, Zxx = signal.stft(x, fs, **kwargs)\n",
    "\n",
    "    Zxx = Zxx[:clip_fs]\n",
    "    f = f[:clip_fs]\n",
    "\n",
    "    Zxx = np.abs(Zxx)\n",
    "    clip = 5  # To handle boundary effects\n",
    "    if normalizing == \"zscore\":\n",
    "        Zxx = Zxx[:, clip:-clip]\n",
    "        Zxx = stats.zscore(Zxx, axis=-1)\n",
    "        t = t[clip:-clip]\n",
    "    elif normalizing == \"baselined\":\n",
    "        Zxx = baseline(Zxx[:, clip:-clip])\n",
    "        t = t[clip:-clip]\n",
    "    elif normalizing == \"db\":\n",
    "        Zxx = np.log2(Zxx[:, clip:-clip])\n",
    "        t = t[clip:-clip]\n",
    "\n",
    "    if np.isnan(Zxx).any():\n",
    "        import pdb\n",
    "\n",
    "        pdb.set_trace()\n",
    "\n",
    "    return f, t, Zxx\n",
    "\n",
    "\n",
    "def plot_stft(wav, SamplingFrequency):\n",
    "    f, t, linear = get_stft(\n",
    "        wav,\n",
    "        SamplingFrequency,\n",
    "        clip_fs=40,\n",
    "        nperseg=400,\n",
    "        noverlap=350,\n",
    "        normalizing=\"zscore\",\n",
    "        return_onesided=True,\n",
    "    )  # TODO hardcode sampling rate\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    g1 = plt.pcolormesh(t, f, linear, shading=\"gouraud\", vmin=-3, vmax=5)\n",
    "\n",
    "    cbar = plt.colorbar(g1)\n",
    "    tick_font_size = 15\n",
    "    cbar.ax.tick_params(labelsize=tick_font_size)\n",
    "    cbar.ax.set_ylabel(\"Power (Arbitrary units)\", fontsize=15)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.ylabel(\"\")\n",
    "    plt.yticks(fontsize=20)\n",
    "    plt.xlabel(\"Time (s)\", fontsize=20)\n",
    "    plt.ylabel(\"Frequency (Hz)\", fontsize=20)\n",
    "\n",
    "\n",
    "def build_model(cfg):\n",
    "    ckpt_path = cfg.upstream_ckpt\n",
    "    init_state = init_state = torch.load(ckpt_path, weights_only=False)\n",
    "    upstream_cfg = init_state[\"model_cfg\"]\n",
    "    upstream = models.build_model(upstream_cfg)\n",
    "    return upstream\n",
    "\n",
    "\n",
    "def load_model_weights(model, states, multi_gpu):\n",
    "    if multi_gpu:\n",
    "        model.module.load_weights(states)\n",
    "    else:\n",
    "        model.load_weights(states)\n",
    "\n",
    "\n",
    "def initialize_model(ckpt_path: str):\n",
    "    \"\"\"\n",
    "    Инициализация модели с заданным путем к контрольной точке (checkpoint).\n",
    "\n",
    "    Args:\n",
    "        ckpt_path (str): Путь к файлу контрольной точки.\n",
    "\n",
    "    Returns:\n",
    "        model: Инициализированная модель.\n",
    "    \"\"\"\n",
    "\n",
    "    # Создание конфигурации и загрузка модели\n",
    "    cfg = OmegaConf.create({\"upstream_ckpt\": ckpt_path})\n",
    "    model = build_model(cfg)\n",
    "    model.to(\"cuda\")\n",
    "\n",
    "    # Загрузка весов модели\n",
    "    init_state = torch.load(ckpt_path, weights_only=False)\n",
    "    load_model_weights(model, init_state[\"model\"], False)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def create_save_dir(base_path: str) -> str:\n",
    "    \"\"\"Создаёт директорию с именем, основанным на текущей дате и времени.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    save_dir = os.path.join(base_path, timestamp)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    return save_dir\n",
    "\n",
    "\n",
    "def read_intervals_from_csv(file_path: str):\n",
    "    \"\"\"Читает интервалы из CSV-файла.\"\"\"\n",
    "    intervals = []\n",
    "    activities = []\n",
    "    with open(file_path, mode=\"r\", encoding=\"utf-8\") as csv_file:\n",
    "        csv_reader = csv.reader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            activities.append(row[0])\n",
    "            intervals.append((float(row[1]), float(row[2])))\n",
    "    return activities, intervals\n",
    "\n",
    "\n",
    "def extract_intervals(original_file_path):\n",
    "    \"\"\"\n",
    "    Преобразует оригинальный TSV файл в переменные для дальнейшей работы: activities, intervals и activity_type.\n",
    "\n",
    "    Args:\n",
    "        original_file_path (str): Путь к оригинальному TSV файлу.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Три списка - activities, intervals и activity_type.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    # Чтение оригинального TSV файла\n",
    "    df = pd.read_csv(original_file_path, sep=\"\\t\")\n",
    "\n",
    "    # Извлечение необходимых столбцов\n",
    "    required_columns = [\n",
    "        \"onset\",\n",
    "        \"duration\",\n",
    "        \"item_name\",\n",
    "        \"trial_type\",\n",
    "        \"test\",\n",
    "        \"answer\",\n",
    "    ]\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        raise ValueError(\n",
    "            f\"Оригинальный файл должен содержать столбцы: {required_columns}\"\n",
    "        )\n",
    "\n",
    "    # Формирование интервалов, где конец интервала это onset следующего элемента\n",
    "    onset_list = df[\"onset\"].tolist() + [0]  # Добавляем 0 в конец\n",
    "    intervals = [(onset_list[i], onset_list[i + 1]) for i in range(len(onset_list) - 1)]\n",
    "\n",
    "    # Формирование activity_type\n",
    "    activity_type = df[\"trial_type\"].tolist()\n",
    "\n",
    "    # Формирование activities с условием для PROB\n",
    "    activities = [\n",
    "        f\"{test} = {answer}\" if trial_type == \"PROB\" else item_name\n",
    "        for test, answer, trial_type, item_name in zip(\n",
    "            df[\"test\"], df[\"answer\"], df[\"trial_type\"], df[\"item_name\"]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    return activities, intervals, activity_type\n",
    "\n",
    "\n",
    "def calculate_metrics(data: np.ndarray):\n",
    "    \"\"\"Вычисляет метрики для данных.\"\"\"\n",
    "    return {\n",
    "        \"mean\": np.mean(data),\n",
    "        \"std\": np.std(data),\n",
    "        \"median\": np.median(data),\n",
    "    }\n",
    "\n",
    "\n",
    "# def generate_stft_data(recording, chosen_rec, intervals, fs):\n",
    "#     \"\"\"Генерирует данные STFT для каждого интервала.\"\"\"\n",
    "#     model_outputs = []\n",
    "#     # Обработка интервалов\n",
    "#     for start, end in intervals:\n",
    "#         # Генерация STFT для всех каналов\n",
    "#         stfts = []\n",
    "#         for channel in range(recording[chosen_rec].shape[0]):\n",
    "#             start_idx = int(start * fs)\n",
    "#             end_idx = int(end * fs)\n",
    "#             f, t, linear = get_stft(\n",
    "#                 recording[chosen_rec][channel, start_idx:end_idx],\n",
    "#                 fs,\n",
    "#                 clip_fs=40,\n",
    "#                 nperseg=400,\n",
    "#                 noverlap=350,\n",
    "#                 normalizing=\"zscore\",\n",
    "#             )\n",
    "#             stfts.append(linear)\n",
    "#         # Форматирование тензоров и инференс модели\n",
    "#         inputs = torch.FloatTensor(np.stack(stfts)).transpose(1, 2).to(\"cuda\")\n",
    "#         mask = torch.zeros((inputs.shape[:2])).bool().to(\"cuda\")\n",
    "\n",
    "#         with torch.no_grad():\n",
    "#             out = model.forward(inputs, mask, intermediate_rep=True)\n",
    "\n",
    "#         model_outputs.append(out.cpu().numpy())\n",
    "#     return model_outputs\n",
    "\n",
    "\n",
    "# def save_interval_visualizations(intervals, model_outputs, activities, save_dir, num_electrodes, selected_electrodes):\n",
    "#     \"\"\"Генерирует и сохраняет визуализации для одного интервала.\"\"\"\n",
    "#     pdf = FPDF(orientation=\"L\", unit=\"mm\", format=\"A4\")\n",
    "#     for interval_idx, (start, end) in enumerate(intervals):\n",
    "#         interval_output = model_outputs[interval_idx]\n",
    "#         interval = intervals[interval_idx]\n",
    "#         activity = activities[interval_idx]\n",
    "\n",
    "#         # Расчёт средней активности на каждом электроде\n",
    "#         median_activity = np.median(np.linalg.norm(interval_output, axis=2), axis=1)\n",
    "\n",
    "#         # Выбор электродов с наибольшей и наименьшей активностью\n",
    "#         most_active_electrodes = np.argsort(median_activity)[-num_electrodes:]  # наибольшая активность\n",
    "#         least_active_electrodes = np.argsort(median_activity)[:num_electrodes]  # наименьшая активность\n",
    "\n",
    "#         for category, electrodes in zip(\n",
    "#             [\"Наибольшая активность\", \"Наименьшая активность\", \"Избранное\"],\n",
    "#             [most_active_electrodes, least_active_electrodes, selected_electrodes],\n",
    "#         ):\n",
    "#             fig, axs = plt.subplots(2, 4, figsize=(16, 8), constrained_layout=True)\n",
    "#             axs = axs.flatten()\n",
    "\n",
    "#             for i, ax in enumerate(axs):\n",
    "#                 if i >= len(electrodes):\n",
    "#                     ax.axis(\"off\")\n",
    "#                     continue\n",
    "\n",
    "#                 electrode = electrodes[i]\n",
    "#                 electrode_data = interval_output[electrode]\n",
    "\n",
    "#                 # Метрики\n",
    "#                 metrics = calculate_metrics(electrode_data.flatten())\n",
    "#                 mean, std, median = metrics[\"mean\"], metrics[\"std\"], metrics[\"median\"]\n",
    "\n",
    "#                 # Построение графика\n",
    "#                 im = ax.imshow(electrode_data, aspect=\"auto\", origin=\"lower\", cmap=\"viridis\")\n",
    "#                 ax.set_title(f\"Электрод {electrode}\")\n",
    "#                 ax.set_xlabel(\"Скрытое измерение\")\n",
    "#                 ax.set_ylabel(\"Временные шаги\")\n",
    "#                 fig.colorbar(im, ax=ax, label=\"Активность\")\n",
    "\n",
    "#                 # Метрики на графике\n",
    "#                 ax.text(\n",
    "#                     0.95,\n",
    "#                     0.95,\n",
    "#                     f\"Mean: {mean:.2f}\\nSTD: {std:.2f}\\nMedian: {median:.2f}\",\n",
    "#                     transform=ax.transAxes,\n",
    "#                     fontsize=8,\n",
    "#                     va=\"top\",\n",
    "#                     ha=\"right\",\n",
    "#                     bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n",
    "#                 )\n",
    "\n",
    "#             plt.suptitle(\n",
    "#                 f\"Интервал {start:.3f}-{end:.3f} сек, активность {activity}, {category}\"\n",
    "#             )\n",
    "\n",
    "#             # Сохранение страницы\n",
    "#             image_path = os.path.join(save_dir, f\"interval_{interval_idx}_{category}.png\")\n",
    "#             plt.savefig(image_path, dpi=300)\n",
    "#             plt.close()\n",
    "\n",
    "#             pdf.add_page()\n",
    "#             pdf.image(image_path, x=10, y=10, w=277)\n",
    "\n",
    "#     pdf_output_path = os.path.join(save_dir, f\"electrode_intervals.pdf\")\n",
    "#     pdf.output(pdf_output_path)\n",
    "\n",
    "\n",
    "def generate_stft_data(recording, chosen_rec, interval, fs):\n",
    "    \"\"\"Генерирует данные STFT для одного указанного интервала записи.\"\"\"\n",
    "    num_channels = recording[chosen_rec].shape[0]\n",
    "    start, end = interval\n",
    "    start_idx = int(start * fs)\n",
    "    end_idx = int(end * fs)\n",
    "\n",
    "    full_stfts = []\n",
    "    for channel in range(num_channels):\n",
    "        f, t, linear = get_stft(\n",
    "            recording[chosen_rec][channel, start_idx:end_idx],\n",
    "            fs,\n",
    "            clip_fs=40,\n",
    "            nperseg=400,\n",
    "            noverlap=350,\n",
    "            normalizing=\"zscore\",\n",
    "        )\n",
    "        full_stfts.append(linear)\n",
    "\n",
    "    return np.stack(full_stfts), f, t\n",
    "\n",
    "\n",
    "def get_model_outputs(stfts, model):\n",
    "    # Форматирование тензоров и инференс модели\n",
    "    inputs = torch.FloatTensor(np.stack(stfts)).transpose(1, 2).to(\"cuda\")\n",
    "    mask = torch.zeros((inputs.shape[:2])).bool().to(\"cuda\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.forward(inputs, mask, intermediate_rep=True)\n",
    "    return out\n",
    "\n",
    "\n",
    "def save_visualizations(\n",
    "    full_stfts,\n",
    "    f,\n",
    "    t,\n",
    "    start,\n",
    "    end,\n",
    "    model_outputs,\n",
    "    intervals,\n",
    "    activities,\n",
    "    save_dir,\n",
    "    num_channels,\n",
    "):\n",
    "    \"\"\"Генерирует визуализации для целой STFT и эмбеддингов с маркировкой активности.\"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    # pdf = FPDF(orientation=\"L\", unit=\"mm\", format=\"A4\")\n",
    "\n",
    "    # Устанавливаем границы визуализации\n",
    "    if start is None:\n",
    "        start = t[0]\n",
    "    if end is None:\n",
    "        end = t[-1]\n",
    "\n",
    "    # Перевод времени в бины\n",
    "    start_bin = int((start - t[0]) / (t[1] - t[0]))\n",
    "    end_bin = int((end - t[0]) / (t[1] - t[0]))\n",
    "\n",
    "    # Вычисляем глобальный минимум и максимум для STFT\n",
    "    stft_global_min = min(stft.min() for stft in full_stfts)\n",
    "    stft_global_max = max(stft.max() for stft in full_stfts)\n",
    "\n",
    "    # Визуализация STFT с интервалами\n",
    "    for channel_idx in num_channels:\n",
    "        fig, ax = plt.subplots(figsize=(16, 10), constrained_layout=True)\n",
    "        im = ax.imshow(\n",
    "            full_stfts[channel_idx],\n",
    "            aspect=\"auto\",\n",
    "            origin=\"lower\",\n",
    "            extent=[start, end, f[0], f[-1]],  # Шкала по секундам\n",
    "            cmap=\"viridis\",\n",
    "            vmin=stft_global_min,  # Фиксируем минимум\n",
    "            vmax=stft_global_max,  # Фиксируем максимум\n",
    "        )\n",
    "        ax.set_title(f\"Channel {channel_idx} - STFT with intervals\")\n",
    "        ax.set_xlabel(\"Time (bins)\")\n",
    "        ax.set_ylabel(\"Frequency (Hz)\")\n",
    "        fig.colorbar(im, ax=ax, label=\"Amplitude\")\n",
    "\n",
    "        # Добавляем интервалы и активности\n",
    "        for (int_start, int_end), activity in zip(intervals, activities):\n",
    "            if (\n",
    "                int_start >= start and int_end <= end\n",
    "            ):  # Ограничиваем по выбранному масштабу\n",
    "                ax.axvline(int_start, color=\"red\", linestyle=\"--\")\n",
    "                ax.axvline(int_end, color=\"blue\", linestyle=\"--\")\n",
    "                ax.text(\n",
    "                    (int_start + int_end) / 2,\n",
    "                    f[0] - (f[-1] * 0.1),  # Разместить под координатной осью\n",
    "                    activity,\n",
    "                    color=\"black\",\n",
    "                    fontsize=8,\n",
    "                    ha=\"center\",\n",
    "                    va=\"top\",\n",
    "                    rotation=90,  # Поворот текста против часовой стрелки\n",
    "                    bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n",
    "                )\n",
    "\n",
    "        image_path = os.path.join(save_dir, f\"stft_channel_{channel_idx}.png\")\n",
    "        plt.savefig(image_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "        # pdf.add_page()\n",
    "        # pdf.image(image_path, x=10, y=10, w=277)\n",
    "\n",
    "    # Вычисляем глобальный минимум и максимум для эмбеддингов\n",
    "    embeddings_global_min = min(\n",
    "        model_outputs[channel_idx].min().item() for channel_idx in num_channels\n",
    "    )\n",
    "    embeddings_global_max = max(\n",
    "        model_outputs[channel_idx].max().item() for channel_idx in num_channels\n",
    "    )\n",
    "\n",
    "    # Визуализация эмбеддингов\n",
    "    for channel_idx in num_channels:\n",
    "        fig, ax = plt.subplots(figsize=(16, 10), constrained_layout=True)\n",
    "        channel_output = model_outputs[channel_idx].cpu().numpy()\n",
    "\n",
    "        im = ax.imshow(\n",
    "            channel_output.T,\n",
    "            aspect=\"auto\",\n",
    "            origin=\"lower\",\n",
    "            extent=[start, end, 0, channel_output.shape[0]],  # Шкала времени в секундах\n",
    "            cmap=\"viridis\",\n",
    "            vmin=embeddings_global_min,  # Фиксируем минимум\n",
    "            vmax=embeddings_global_max,  # Фиксируем максимум\n",
    "        )\n",
    "        ax.set_title(f\"Channel {channel_idx} - Embeddings with intervals\")\n",
    "        ax.set_xlabel(\"Time (bins)\")\n",
    "        ax.set_ylabel(\"Embedding\")\n",
    "        fig.colorbar(im, ax=ax, label=\"Activity\")\n",
    "\n",
    "        # Добавляем интервалы и активности\n",
    "        for (int_start, int_end), activity in zip(intervals, activities):\n",
    "            if (\n",
    "                int_start >= start and int_end <= end\n",
    "            ):  # Ограничиваем по выбранному масштабу\n",
    "                ax.axvline(int_start, color=\"red\", linestyle=\"--\")\n",
    "                ax.axvline(int_end, color=\"blue\", linestyle=\"--\")\n",
    "                ax.text(\n",
    "                    (int_start + int_end) / 2,\n",
    "                    -channel_output.shape[0] * 0.1,  # Разместить под координатной осью\n",
    "                    activity,\n",
    "                    color=\"black\",\n",
    "                    fontsize=8,\n",
    "                    ha=\"center\",\n",
    "                    va=\"top\",\n",
    "                    rotation=90,  # Поворот текста против часовой стрелки\n",
    "                    bbox=dict(boxstyle=\"round\", facecolor=\"white\", alpha=0.8),\n",
    "                )\n",
    "\n",
    "        image_path = os.path.join(save_dir, f\"embeddings_channel_{channel_idx}.png\")\n",
    "        plt.savefig(image_path, dpi=300)\n",
    "        plt.close()\n",
    "\n",
    "    #     pdf.add_page()\n",
    "    #     pdf.image(image_path, x=10, y=10, w=277)\n",
    "\n",
    "    # pdf_output_path = os.path.join(save_dir, \"visualizations.pdf\")\n",
    "    # pdf.output(pdf_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f1c371fd-4ce2-438f-9ef7-3f8975135133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализация временных интервалов\n",
    "def normalize_intervals(intervals, t_bins, start):\n",
    "    adjusted_t_bins = t_bins + start  # Учет смещения временного массива\n",
    "    normalized_intervals = []\n",
    "    for int_start, int_end in intervals:\n",
    "        start_idx = np.searchsorted(adjusted_t_bins, int_start, side=\"left\")\n",
    "        end_idx = np.searchsorted(adjusted_t_bins, int_end, side=\"right\")\n",
    "        # Проверяем, что индекс начала меньше индекса конца\n",
    "        if start_idx < end_idx:\n",
    "            normalized_intervals.append((start_idx, end_idx))\n",
    "        else:\n",
    "            print(\n",
    "                f\"Invalid interval: ({int_start}, {int_end}) mapped to ({start_idx}, {end_idx})\"\n",
    "            )\n",
    "    print(f\"Normalized intervals: {normalized_intervals}\")\n",
    "    return normalized_intervals\n",
    "\n",
    "\n",
    "# Усреднение данных в интервалах\n",
    "def average_data_in_intervals(data, intervals):\n",
    "    averaged_vectors = []\n",
    "    for start_idx, end_idx in intervals:\n",
    "        if start_idx < end_idx:\n",
    "            interval_data = data[..., start_idx:end_idx]\n",
    "            if np.isnan(interval_data).any():\n",
    "                print(\n",
    "                    f\"NaN detected in interval {start_idx}-{end_idx}, data: {interval_data}\"\n",
    "                )\n",
    "            averaged = np.nanmean(interval_data, axis=-1)  # Обработка NaN\n",
    "            averaged_vectors.append(averaged)\n",
    "        else:\n",
    "            print(f\"Skipping interval with invalid indices: {start_idx}-{end_idx}\")\n",
    "    averaged_vectors = np.array(averaged_vectors)\n",
    "    print(f\"Averaged data shape: {averaged_vectors.shape}\")\n",
    "    return averaged_vectors\n",
    "\n",
    "\n",
    "def sovu_na_globus(intervals, t_bins, start, activity):\n",
    "    \"\"\"\n",
    "    Назначает метки активности интервалам временного массива.\n",
    "\n",
    "    Параметры:\n",
    "    - intervals (list of tuples): Список интервалов (start, end).\n",
    "    - t_bins (np.ndarray): Массив временных отметок (бинов).\n",
    "    - start (float): Смещение временного массива.\n",
    "    - activity (list): Список меток активности для каждого интервала.\n",
    "\n",
    "    Возвращает:\n",
    "    - bin_labels (np.ndarray): Массив меток активности для каждого бина.\n",
    "    \"\"\"\n",
    "    # Учет смещения временного массива\n",
    "    adjusted_t_bins = t_bins + start\n",
    "    # Создаем массив с типом object для поддержки строковых меток\n",
    "    bin_labels = np.zeros_like(adjusted_t_bins, dtype=object)\n",
    "\n",
    "    # Присвоение активности интервалам\n",
    "    for i, (int_start, int_end) in enumerate(intervals):\n",
    "        start_idx = np.searchsorted(adjusted_t_bins, int_start, side=\"left\")\n",
    "        end_idx = np.searchsorted(adjusted_t_bins, int_end, side=\"right\")\n",
    "\n",
    "        # Проверяем корректность индексов и присваиваем метки\n",
    "        if start_idx < end_idx:\n",
    "            bin_labels[start_idx:end_idx] = activity[i]\n",
    "        else:\n",
    "            print(\n",
    "                f\"Invalid interval: ({int_start}, {int_end}) mapped to ({start_idx}, {end_idx})\"\n",
    "            )\n",
    "\n",
    "    return bin_labels\n",
    "\n",
    "\n",
    "def within_interval(test, left, right):\n",
    "    if test >= left and test <= right:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def return_state(test1, test2, left, right):\n",
    "    return f\"{within_interval(test1, left, right)}{within_interval(test2, left, right)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc9380ab-fd21-4776-8701-e6fa151f4767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_visualizations_with_projections(\n",
    "    full_stfts,\n",
    "    f,\n",
    "    t,\n",
    "    start,\n",
    "    end,\n",
    "    model_outputs,\n",
    "    intervals,\n",
    "    activities,\n",
    "    activity_type,\n",
    "    save_dir,\n",
    "    num_channels,\n",
    "    iteration,\n",
    "    pca,\n",
    "):\n",
    "    \"\"\"\n",
    "    Генерирует визуализации STFT, эмбеддингов и их проекций (PCA, t-SNE, UMAP).\n",
    "    \"\"\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    # pdf = FPDF(orientation=\"L\", unit=\"mm\", format=\"A4\")\n",
    "\n",
    "    # Цвета для activity_type\n",
    "    unique_activity_types = list(set(activity_type))\n",
    "    colors = plt.cm.tab10(np.linspace(0, 1, len(unique_activity_types)))\n",
    "    activity_color_map = {\n",
    "        atype: color for atype, color in zip(unique_activity_types, colors)\n",
    "    }\n",
    "\n",
    "    def plot_projections(averaged_data, activity_type, title, file_prefix, pca):\n",
    "        avg_vector_1_list = []\n",
    "        avg_vector_2_list = []\n",
    "        activity_color_map_list = []\n",
    "        \"\"\"Рисует проекции PCA, t-SNE, UMAP для одного канала.\"\"\"\n",
    "        print(f\"Processing {title}, data shape: {averaged_data.shape}\")\n",
    "        if averaged_data.shape[0] == 0:\n",
    "            print(f\"Пропущен канал для {title}, данные отсутствуют.\")\n",
    "            return\n",
    "\n",
    "        # Проверка на минимальный размер выборки\n",
    "        if averaged_data.shape[0] < 2:\n",
    "            print(f\"Недостаточно данных для проекций в {title}, пропущено.\")\n",
    "            return\n",
    "\n",
    "        # Обработка NaN перед обучением моделей\n",
    "        if np.isnan(averaged_data).any():\n",
    "            print(f\"Данные содержат NaN в {title}, пропущено.\")\n",
    "            return\n",
    "\n",
    "        print(f\"Averaged data before projection: {averaged_data}\")\n",
    "        if iteration == 0:\n",
    "            pca = PCA(n_components=2).fit(averaged_data)\n",
    "        proj = pca.transform(averaged_data)\n",
    "        # tsne = TSNE(n_components=2, perplexity=min(30, averaged_data.shape[0] - 1), random_state=42).fit_transform(averaged_data)\n",
    "        # umap_proj = umap.UMAP(n_components=2, random_state=42).fit_transform(averaged_data)\n",
    "\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "        plt.subplots_adjust(right=0.90)  # Оставляем 15% ширины для легенды\n",
    "        # projections = [(pca, \"PCA\"), (tsne, \"t-SNE\"), (umap_proj, \"UMAP\")]\n",
    "        projections = [(proj, \"PCA\")]\n",
    "        for ax, (proj, method) in zip(axs, projections):\n",
    "            print(f\"Plotting {method} for {title}\")\n",
    "            # for avg_vector, activity, atype in zip(proj, activities, activity_type):\n",
    "            for avg_vector, atype in zip(proj, activity_type):\n",
    "                if atype not in activity_color_map:\n",
    "                    print(f\"Missing color for activity type: {atype}\")\n",
    "                # ax.scatter(avg_vector[0], avg_vector[1], label=activity, color=activity_color_map[atype], edgecolor=\"k\")\n",
    "                ax.scatter(\n",
    "                    avg_vector[0],\n",
    "                    avg_vector[1],\n",
    "                    color=activity_color_map[atype],\n",
    "                    edgecolor=\"k\",\n",
    "                )\n",
    "                avg_vector_1_list.append(avg_vector[0])\n",
    "                avg_vector_2_list.append(avg_vector[1])\n",
    "                activity_color_map_list.append(activity_color_map[atype])\n",
    "                # ax.text(\n",
    "                #     avg_vector[0], avg_vector[1], activity,\n",
    "                #     fontsize=8, ha=\"center\", va=\"bottom\",\n",
    "                #     bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"none\", facecolor=\"white\", alpha=0.8)\n",
    "                # )\n",
    "            ax.set_title(f\"{method} - {title}\")\n",
    "            ax.set_xlabel(\"Component 1\")\n",
    "            ax.set_ylabel(\"Component 2\")\n",
    "\n",
    "        # # Создаем легенду с элементами для всех типов активности\n",
    "        # handles = [\n",
    "        #     plt.Line2D([0], [0], marker='o', color='w', label=atype,\n",
    "        #                markerfacecolor=color, markersize=10)\n",
    "        #     for atype, color in activity_color_map.items()\n",
    "        # ]\n",
    "\n",
    "        # # Проверяем, что handles не пустой\n",
    "        # if handles:\n",
    "        #     fig.legend(\n",
    "        #         handles=handles,\n",
    "        #         title=\"Activity Type\",\n",
    "        #         loc=\"center left\",             # Привязываем к левому краю области для легенды\n",
    "        #         bbox_to_anchor=(0.90, 0.5),     # Центрируем вертикально\n",
    "        #         borderaxespad=0.0,             # Убираем лишние отступы\n",
    "        #         frameon=False                  # Убираем рамку вокруг легенды\n",
    "        #     )\n",
    "        # else:\n",
    "        #     print(\"Warning: No handles for legend. Check activity_color_map and activity_type.\")\n",
    "\n",
    "        # output_path = os.path.join(save_dir, f\"{file_prefix}_projections.png\")\n",
    "        # plt.savefig(output_path, dpi=300)\n",
    "        # plt.close()\n",
    "\n",
    "        # pdf.add_page()\n",
    "        # pdf.image(output_path, x=10, y=10, w=277)\n",
    "        return pca, avg_vector_1_list, avg_vector_2_list, activity_color_map_list\n",
    "\n",
    "    model_outputs = np.transpose(model_outputs.cpu().numpy(), (0, 1, 2))\n",
    "    full_stfts = np.transpose(full_stfts, (0, 2, 1))\n",
    "\n",
    "    # # Проекции STFT\n",
    "    # for channel_idx in num_channels:\n",
    "    #     print(f\"Processing STFT for channel {channel_idx}\")\n",
    "    #     if channel_idx >= len(full_stfts):\n",
    "    #         print(f\"Канал {channel_idx} выходит за пределы full_stfts.\")\n",
    "    #         continue\n",
    "    #     # normalized_intervals = normalize_intervals(intervals, t, start)\n",
    "    #     normalized_intervals = sovu_na_globus(intervals, t, start, activity_type)\n",
    "    #     channel_data = full_stfts[channel_idx]\n",
    "    #     print(f\"Raw STFT data for channel {channel_idx}:\\n{channel_data}\")\n",
    "    #     # averaged_data = average_data_in_intervals(channel_data, normalized_intervals)\n",
    "    #     # plot_projections(\n",
    "    #     #     averaged_data, activities, activity_type,\n",
    "    #     plot_projections(\n",
    "    #         channel_data, normalized_intervals,\n",
    "    #         title=f\"STFT Channel {channel_idx}\", file_prefix=f\"stft_channel_{channel_idx}\"\n",
    "    #     )\n",
    "\n",
    "    # Проекции эмбеддингов\n",
    "    for channel_idx in num_channels:\n",
    "        print(f\"Processing embeddings for channel {channel_idx}\")\n",
    "        if channel_idx >= len(model_outputs):\n",
    "            print(f\"Канал {channel_idx} выходит за пределы model_outputs.\")\n",
    "            continue\n",
    "        normalized_intervals = sovu_na_globus(intervals, t, start, activity_type)\n",
    "        channel_output = model_outputs[channel_idx]\n",
    "        print(f\"Raw embeddings data for channel {channel_idx}:\\n{channel_output}\")\n",
    "\n",
    "        # averaged_data = average_data_in_intervals(channel_output, normalized_intervals)\n",
    "        # plot_projections(\n",
    "        #     averaged_data, activities, activity_type,\n",
    "        return plot_projections(\n",
    "            channel_output,\n",
    "            normalized_intervals,\n",
    "            title=f\"Embeddings Channel {channel_idx}\",\n",
    "            file_prefix=f\"embeddings_channel_{channel_idx}\",\n",
    "            pca=pca,\n",
    "        )\n",
    "\n",
    "    # pdf_output_path = os.path.join(save_dir, \"visualizations_with_projections.pdf\")\n",
    "    # pdf.output(pdf_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ed6d2b-3bba-4a63-a977-012c4d4adf5b",
   "metadata": {},
   "source": [
    "# Main launchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e1c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Параметры ===\n",
    "# Пути к данным и моделям\n",
    "ckpt_path = \"/trinity/home/asma.benachour/BERT_init_weights/stft_large_pretrained.pth\"\n",
    "path_to = \"/trinity/home/asma.benachour/Haydn Free recall/sub-R1001P/ses-0/ieeg/\"\n",
    "# csv_file_path = \"/beegfs/home/g.soghoyan/George/BERT-intervals/first_intervalR1001P.csv\"\n",
    "tsv_file_path = \"/trinity/home/asma.benachour/Haydn Free recall/sub-R1001P/ses-0/ieeg/sub-R1001P_ses-0_task-FR1_events.tsv\"\n",
    "pdf_output_dir = \"/trinity/home/asma.benachour/PDF/\"\n",
    "\n",
    "os.makedirs(pdf_output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "345cf4dc-9c4c-45c8-b1d4-616050deb632",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/asma.benachour/miniconda3/envs/brainbert/lib/python3.10/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Инициализация модели\n",
    "model = initialize_model(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be04b478-e231-4958-b077-dad0dacc0c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создание директории для сохранения\n",
    "save_dir = create_save_dir(pdf_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "711cfda4-7a87-4e0d-ba83-61c65d7b3761",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to = \"/trinity/home/asma.benachour/Haydn Free recall/sub-R1001P/ses-0/ieeg/\"\n",
    "left_suff = \"sub-R1001P_ses-0_task-FR1_acq-\"\n",
    "right_suff = \"_ieeg.edf\"\n",
    "signal_types = [\"monopolar\", \"bipolar\"]\n",
    "file_name = {}\n",
    "recording = {}\n",
    "signal_labels = {}\n",
    "for s_type in signal_types:\n",
    "    file_name[s_type] = f\"{path_to}{left_suff}{s_type}{right_suff}\"\n",
    "    recording[s_type], signal_labels[s_type] = edf_extractor(file_name[s_type])\n",
    "SamplingFrequency = 500\n",
    "chosen_rec = \"bipolar\"\n",
    "framecap = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c73d177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Извлечённые интервалы трайалов: [[308.201, 407.853], [407.853, 507.522], [507.522, 615.209], [615.209, 711.377], [711.377, 1071.861], [1071.861, 1184.266], [1184.266, 1308.922], [1308.922, 1420.81], [1420.81, 1533.248], [1533.248, 1646.853], [1646.853, 1759.907], [1759.907, 1873.912], [1873.912, 1974.314], [1974.314, 2079.917], [2079.917, 2569.459], [2569.459, 2669.645], [2669.645, 2774.398], [2774.398, 2878.034], [2878.034, 2997.34], [2997.34, 3113.845], [3113.845, 3221.466], [3221.466, 3327.852], [3327.852, 3433.139]]\n"
     ]
    }
   ],
   "source": [
    "# 1. Загрузка поведенческого документа.\n",
    "# Предполагается, что файл имеет разделитель табуляция, если другой – измените sep.\n",
    "behavior_df = pd.read_csv(tsv_file_path, sep=\"\\t\")\n",
    "\n",
    "# 2. Фильтрация строк с маркером начала трайала.\n",
    "# Здесь предполагается, что начало трайала отмечено в столбце \"trial_type\" значением \"TRIAL\".\n",
    "trial_df = behavior_df[behavior_df[\"trial_type\"] == \"TRIAL\"].reset_index(drop=True)\n",
    "\n",
    "# 3. Исключаем первый трайал, если требуется (например, он может быть служебным).\n",
    "trial_df = trial_df.iloc[1:]  # Если нужно исключить первый трайал\n",
    "\n",
    "# 4. Создаем интервалы: для каждой строки берем время начала текущего трайала и время начала следующего.\n",
    "trial_df[\"next_onset\"] = trial_df[\"onset\"].shift(-1)\n",
    "# Убираем последнюю строку, у которой нет следующего onset (т.е. не образует интервал)\n",
    "trial_df = trial_df.dropna(subset=[\"next_onset\"])\n",
    "\n",
    "# Преобразуем интервалы в список пар (start, end)\n",
    "trials = trial_df[[\"onset\", \"next_onset\"]].values.tolist()\n",
    "print(\"Извлечённые интервалы трайалов:\", trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76ce03fa-749e-4998-8b45-df0e3e6d09e2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размерность intervals:756 на 2; Размерность activity_type:756 на 1; Размерность activities:756 на 1\n"
     ]
    }
   ],
   "source": [
    "# Чтение интервалов\n",
    "# activities, intervals = read_intervals_from_csv(csv_file_path)\n",
    "activities, intervals, activity_type = extract_intervals(tsv_file_path)\n",
    "print(\n",
    "    f\"Размерность intervals:{len(intervals)} на {len(intervals[0])}; Размерность activity_type:{len(activity_type)} на 1; Размерность activities:{len(activities)} на 1\"\n",
    ")\n",
    "\n",
    "# 6. Выбор одного случайного электродного канала (один рандомный электрод)\n",
    "num_electrodes = 1\n",
    "num_channels = random.sample(range(72), num_electrodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dd3d63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Фильтрация интервалов по длительности (минимум 400 сэмплов)\n",
    "filtered_idx = []\n",
    "for i, d in enumerate(intervals):\n",
    "    if (d[1] - d[0]) * SamplingFrequency >= 400:\n",
    "        filtered_idx.append(i)\n",
    "threshold_intervals = [intervals[i] for i in filtered_idx]\n",
    "threshold_activities = [activities[i] for i in filtered_idx]\n",
    "threshold_activity_type = [activity_type[i] for i in filtered_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf9b6a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid interval: (308.201, 308.201) mapped to (0, 0)\n",
      "Invalid interval: (308.201, 308.201) mapped to (0, 0)\n",
      "Invalid interval: (318.629, 318.636) mapped to (100, 100)\n",
      "Invalid interval: (350.376, 350.377) mapped to (417, 417)\n",
      "Invalid interval: (350.377, 350.392) mapped to (417, 417)\n",
      "Invalid interval: (373.802, 373.813) mapped to (652, 652)\n",
      "Invalid interval: (407.853, 407.853) mapped to (988, 988)\n",
      "Invalid interval: (407.853, 407.853) mapped to (988, 988)\n",
      "Invalid interval: (407.853, 407.853) mapped to (0, 0)\n",
      "Invalid interval: (407.853, 407.853) mapped to (0, 0)\n",
      "Invalid interval: (418.281, 418.288) mapped to (100, 100)\n",
      "Invalid interval: (450.411, 450.412) mapped to (421, 421)\n",
      "Invalid interval: (450.412, 450.428) mapped to (421, 421)\n",
      "Invalid interval: (470.562, 470.581) mapped to (623, 623)\n",
      "Invalid interval: (507.522, 507.522) mapped to (988, 988)\n",
      "Invalid interval: (507.522, 507.522) mapped to (988, 988)\n",
      "Invalid interval: (507.522, 507.522) mapped to (0, 0)\n",
      "Invalid interval: (507.522, 507.522) mapped to (0, 0)\n",
      "Invalid interval: (517.95, 517.957) mapped to (100, 100)\n",
      "Invalid interval: (549.563, 549.564) mapped to (416, 416)\n",
      "Invalid interval: (549.564, 549.58) mapped to (416, 416)\n",
      "Invalid interval: (572.162, 572.167) mapped to (642, 642)\n",
      "Invalid interval: (615.209, 615.209) mapped to (1068, 1068)\n",
      "Invalid interval: (615.209, 615.209) mapped to (1068, 1068)\n",
      "Invalid interval: (615.209, 615.209) mapped to (0, 0)\n",
      "Invalid interval: (615.209, 615.209) mapped to (0, 0)\n",
      "Invalid interval: (625.637, 625.644) mapped to (100, 100)\n",
      "Invalid interval: (656.916, 656.917) mapped to (413, 413)\n",
      "Invalid interval: (656.917, 656.933) mapped to (413, 413)\n",
      "Invalid interval: (677.154, 677.17) mapped to (615, 615)\n",
      "Invalid interval: (708.259, 708.269) mapped to (926, 926)\n",
      "Invalid interval: (711.377, 711.377) mapped to (953, 953)\n",
      "Invalid interval: (711.377, 711.377) mapped to (953, 953)\n",
      "Invalid interval: (711.377, 711.377) mapped to (0, 0)\n",
      "Invalid interval: (711.377, 711.377) mapped to (0, 0)\n",
      "Invalid interval: (721.805, 721.812) mapped to (100, 100)\n",
      "Invalid interval: (753.035, 753.035) mapped to (412, 412)\n",
      "Invalid interval: (753.035, 753.051) mapped to (412, 412)\n",
      "Invalid interval: (781.362, 781.373) mapped to (695, 695)\n",
      "Invalid interval: (812.418, 812.424) mapped to (1006, 1006)\n",
      "Invalid interval: (1071.861, 1071.861) mapped to (3596, 3596)\n",
      "Invalid interval: (1071.861, 1071.861) mapped to (3596, 3596)\n",
      "Invalid interval: (1071.861, 1071.861) mapped to (0, 0)\n",
      "Invalid interval: (1071.861, 1071.861) mapped to (0, 0)\n",
      "Invalid interval: (1082.289, 1082.296) mapped to (100, 100)\n",
      "Invalid interval: (1114.119, 1114.12) mapped to (418, 418)\n",
      "Invalid interval: (1114.12, 1114.136) mapped to (418, 418)\n",
      "Invalid interval: (1145.098, 1145.108) mapped to (728, 728)\n",
      "Invalid interval: (1184.266, 1184.266) mapped to (1116, 1116)\n",
      "Invalid interval: (1184.266, 1184.266) mapped to (1116, 1116)\n",
      "Invalid interval: (1184.266, 1184.266) mapped to (0, 0)\n",
      "Invalid interval: (1184.266, 1184.266) mapped to (0, 0)\n",
      "Invalid interval: (1194.694, 1194.7) mapped to (100, 100)\n",
      "Invalid interval: (1226.007, 1226.008) mapped to (413, 413)\n",
      "Invalid interval: (1226.008, 1226.023) mapped to (413, 413)\n",
      "Invalid interval: (1263.298, 1263.314) mapped to (786, 786)\n",
      "Invalid interval: (1308.922, 1308.922) mapped to (1238, 1238)\n",
      "Invalid interval: (1308.922, 1308.922) mapped to (1238, 1238)\n",
      "Invalid interval: (1308.922, 1308.922) mapped to (0, 0)\n",
      "Invalid interval: (1308.922, 1308.922) mapped to (0, 0)\n",
      "Invalid interval: (1319.35, 1319.358) mapped to (100, 100)\n",
      "Invalid interval: (1351.014, 1351.014) mapped to (416, 416)\n",
      "Invalid interval: (1420.81, 1420.81) mapped to (1110, 1110)\n",
      "Invalid interval: (1420.81, 1420.81) mapped to (1110, 1110)\n",
      "Invalid interval: (1420.81, 1420.81) mapped to (0, 0)\n",
      "Invalid interval: (1420.81, 1420.81) mapped to (0, 0)\n",
      "Invalid interval: (1431.238, 1431.245) mapped to (100, 100)\n",
      "Invalid interval: (1462.717, 1462.718) mapped to (415, 415)\n",
      "Invalid interval: (1462.718, 1462.734) mapped to (415, 415)\n",
      "Invalid interval: (1491.737, 1491.757) mapped to (705, 705)\n",
      "Invalid interval: (1533.248, 1533.248) mapped to (1116, 1116)\n",
      "Invalid interval: (1533.248, 1533.248) mapped to (1116, 1116)\n",
      "Invalid interval: (1533.248, 1533.248) mapped to (0, 0)\n",
      "Invalid interval: (1533.248, 1533.248) mapped to (0, 0)\n",
      "Invalid interval: (1543.676, 1543.682) mapped to (100, 100)\n",
      "Invalid interval: (1575.106, 1575.107) mapped to (414, 414)\n",
      "Invalid interval: (1575.107, 1575.122) mapped to (414, 414)\n",
      "Invalid interval: (1600.673, 1600.693) mapped to (670, 670)\n",
      "Invalid interval: (1646.853, 1646.853) mapped to (1128, 1128)\n",
      "Invalid interval: (1646.853, 1646.853) mapped to (1128, 1128)\n",
      "Invalid interval: (1646.853, 1646.853) mapped to (0, 0)\n",
      "Invalid interval: (1646.853, 1646.853) mapped to (0, 0)\n",
      "Invalid interval: (1657.281, 1657.288) mapped to (100, 100)\n",
      "Invalid interval: (1688.894, 1688.895) mapped to (416, 416)\n",
      "Invalid interval: (1688.895, 1688.91) mapped to (416, 416)\n",
      "Invalid interval: (1713.602, 1713.615) mapped to (663, 663)\n",
      "Invalid interval: (1759.907, 1759.907) mapped to (1122, 1122)\n",
      "Invalid interval: (1759.907, 1759.907) mapped to (1122, 1122)\n",
      "Invalid interval: (1759.907, 1759.907) mapped to (0, 0)\n",
      "Invalid interval: (1759.907, 1759.907) mapped to (0, 0)\n",
      "Invalid interval: (1770.335, 1770.342) mapped to (100, 100)\n",
      "Invalid interval: (1802.082, 1802.083) mapped to (417, 417)\n",
      "Invalid interval: (1802.083, 1802.098) mapped to (417, 417)\n",
      "Invalid interval: (1832.098, 1832.104) mapped to (717, 717)\n",
      "Invalid interval: (1873.912, 1873.912) mapped to (1132, 1132)\n",
      "Invalid interval: (1873.912, 1873.912) mapped to (1132, 1132)\n",
      "Invalid interval: (1873.912, 1873.912) mapped to (0, 0)\n",
      "Invalid interval: (1873.912, 1873.912) mapped to (0, 0)\n",
      "Invalid interval: (1884.34, 1884.347) mapped to (100, 100)\n",
      "Invalid interval: (1915.903, 1915.904) mapped to (415, 415)\n",
      "Invalid interval: (1937.458, 1937.474) mapped to (631, 631)\n",
      "Invalid interval: (1974.314, 1974.314) mapped to (996, 996)\n",
      "Invalid interval: (1974.314, 1974.314) mapped to (996, 996)\n",
      "Invalid interval: (1974.314, 1974.314) mapped to (0, 0)\n",
      "Invalid interval: (1974.314, 1974.314) mapped to (0, 0)\n",
      "Invalid interval: (1984.742, 1984.749) mapped to (100, 100)\n",
      "Invalid interval: (2016.072, 2016.073) mapped to (413, 413)\n",
      "Invalid interval: (2016.073, 2016.089) mapped to (413, 413)\n",
      "Invalid interval: (2042.018, 2042.027) mapped to (673, 673)\n",
      "Invalid interval: (2079.917, 2079.917) mapped to (1048, 1048)\n",
      "Invalid interval: (2079.917, 2079.917) mapped to (1048, 1048)\n",
      "Invalid interval: (2079.917, 2079.917) mapped to (0, 0)\n",
      "Invalid interval: (2079.917, 2079.917) mapped to (0, 0)\n",
      "Invalid interval: (2090.345, 2090.353) mapped to (100, 100)\n",
      "Invalid interval: (2122.442, 2122.443) mapped to (421, 421)\n",
      "Invalid interval: (2122.443, 2122.459) mapped to (421, 421)\n",
      "Invalid interval: (2142.45, 2142.462) mapped to (621, 621)\n",
      "Invalid interval: (2569.459, 2569.459) mapped to (4887, 4887)\n",
      "Invalid interval: (2569.459, 2569.459) mapped to (4887, 4887)\n",
      "Invalid interval: (2569.459, 2569.459) mapped to (0, 0)\n",
      "Invalid interval: (2569.459, 2569.459) mapped to (0, 0)\n",
      "Invalid interval: (2579.887, 2579.895) mapped to (100, 100)\n",
      "Invalid interval: (2611.716, 2611.717) mapped to (418, 418)\n",
      "Invalid interval: (2611.717, 2611.733) mapped to (418, 418)\n",
      "Invalid interval: (2634.242, 2634.255) mapped to (643, 643)\n",
      "Invalid interval: (2669.645, 2669.645) mapped to (993, 993)\n",
      "Invalid interval: (2669.645, 2669.645) mapped to (993, 993)\n",
      "Invalid interval: (2669.645, 2669.645) mapped to (0, 0)\n",
      "Invalid interval: (2669.645, 2669.645) mapped to (0, 0)\n",
      "Invalid interval: (2680.073, 2680.08) mapped to (100, 100)\n",
      "Invalid interval: (2711.786, 2711.787) mapped to (417, 417)\n",
      "Invalid interval: (2711.787, 2711.803) mapped to (417, 417)\n",
      "Invalid interval: (2736.554, 2736.557) mapped to (665, 665)\n",
      "Invalid interval: (2774.398, 2774.398) mapped to (1039, 1039)\n",
      "Invalid interval: (2774.398, 2774.398) mapped to (1039, 1039)\n",
      "Invalid interval: (2774.398, 2774.398) mapped to (0, 0)\n",
      "Invalid interval: (2774.398, 2774.398) mapped to (0, 0)\n",
      "Invalid interval: (2784.826, 2784.833) mapped to (100, 100)\n",
      "Invalid interval: (2816.472, 2816.473) mapped to (416, 416)\n",
      "Invalid interval: (2816.473, 2816.489) mapped to (416, 416)\n",
      "Invalid interval: (2840.37, 2840.377) mapped to (655, 655)\n",
      "Invalid interval: (2878.034, 2878.034) mapped to (1028, 1028)\n",
      "Invalid interval: (2878.034, 2878.034) mapped to (1028, 1028)\n",
      "Invalid interval: (2878.034, 2878.034) mapped to (0, 0)\n",
      "Invalid interval: (2878.034, 2878.034) mapped to (0, 0)\n",
      "Invalid interval: (2888.462, 2888.469) mapped to (100, 100)\n",
      "Invalid interval: (2920.108, 2920.109) mapped to (416, 416)\n",
      "Invalid interval: (2920.109, 2920.125) mapped to (416, 416)\n",
      "Invalid interval: (2949.418, 2949.431) mapped to (709, 709)\n",
      "Invalid interval: (2997.34, 2997.34) mapped to (1185, 1185)\n",
      "Invalid interval: (2997.34, 2997.34) mapped to (1185, 1185)\n",
      "Invalid interval: (2997.34, 2997.34) mapped to (0, 0)\n",
      "Invalid interval: (2997.34, 2997.34) mapped to (0, 0)\n",
      "Invalid interval: (3007.768, 3007.775) mapped to (100, 100)\n",
      "Invalid interval: (3038.998, 3038.998) mapped to (412, 412)\n",
      "Invalid interval: (3038.998, 3039.014) mapped to (412, 412)\n",
      "Invalid interval: (3070.906, 3070.92) mapped to (731, 731)\n",
      "Invalid interval: (3113.845, 3113.845) mapped to (1157, 1157)\n",
      "Invalid interval: (3113.845, 3113.845) mapped to (1157, 1157)\n",
      "Invalid interval: (3113.845, 3113.845) mapped to (0, 0)\n",
      "Invalid interval: (3113.845, 3113.845) mapped to (0, 0)\n",
      "Invalid interval: (3124.273, 3124.28) mapped to (100, 100)\n",
      "Invalid interval: (3155.719, 3155.72) mapped to (414, 414)\n",
      "Invalid interval: (3155.72, 3155.735) mapped to (414, 414)\n",
      "Invalid interval: (3180.29, 3180.307) mapped to (660, 660)\n",
      "Invalid interval: (3221.465, 3221.466) mapped to (1068, 1068)\n",
      "Invalid interval: (3221.466, 3221.466) mapped to (1068, 1068)\n",
      "Invalid interval: (3221.466, 3221.466) mapped to (0, 0)\n",
      "Invalid interval: (3231.893, 3231.9) mapped to (100, 100)\n",
      "Invalid interval: (3263.739, 3263.739) mapped to (418, 418)\n",
      "Invalid interval: (3263.739, 3263.756) mapped to (418, 418)\n",
      "Invalid interval: (3287.41, 3287.428) mapped to (655, 655)\n",
      "Invalid interval: (3327.852, 3327.852) mapped to (1055, 1055)\n",
      "Invalid interval: (3327.852, 3327.852) mapped to (1055, 1055)\n",
      "Invalid interval: (3327.852, 3327.852) mapped to (0, 0)\n",
      "Invalid interval: (3327.852, 3327.852) mapped to (0, 0)\n",
      "Invalid interval: (3338.28, 3338.287) mapped to (100, 100)\n",
      "Invalid interval: (3369.976, 3369.977) mapped to (417, 417)\n",
      "Invalid interval: (3369.977, 3369.993) mapped to (417, 417)\n",
      "Invalid interval: (3395.81, 3395.814) mapped to (675, 675)\n",
      "Invalid interval: (3433.138, 3433.139) mapped to (1044, 1044)\n",
      "Invalid interval: (3433.139, 3433.139) mapped to (1044, 1044)\n"
     ]
    }
   ],
   "source": [
    "all_models = []\n",
    "all_intervals = []\n",
    "for trial_idx, (start, end) in enumerate(trials):\n",
    "    try:\n",
    "        filtered_int_index = []\n",
    "        new_intervals = []\n",
    "        for i, intr in enumerate(intervals):\n",
    "            if return_state(intr[0], intr[1], start, end) == \"11\":\n",
    "                filtered_int_index.append(i)\n",
    "                new_intervals.append((intr[0], intr[1]))\n",
    "            elif return_state(intr[0], intr[1], start, end) == \"10\":\n",
    "                filtered_int_index.append(i)\n",
    "                new_intervals.append((intr[0], end))\n",
    "            elif return_state(intr[0], intr[1], start, end) == \"01\":\n",
    "                filtered_int_index.append(i)\n",
    "                new_intervals.append((start, intr[1]))\n",
    "\n",
    "        # Теперь filtered_digit содержит только те позиции, которые удовлетворяют условию\n",
    "        fit_intervals = new_intervals\n",
    "        fit_activities = [activities[i] for i in filtered_int_index]\n",
    "        fit_activity_type = [activity_type[i] for i in filtered_int_index]\n",
    "        stft_data_array, f, t = generate_stft_data(\n",
    "            recording, chosen_rec, (start, end), SamplingFrequency\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            model_outputs = get_model_outputs(stft_data_array, model)\n",
    "            all_models.append(model_outputs[num_channels[0]].cpu().numpy())\n",
    "            torch.cuda.empty_cache()\n",
    "        all_intervals.append(sovu_na_globus(fit_intervals, t, start, fit_activity_type))\n",
    "    except RuntimeError as e:\n",
    "        print(f\"| WARNING: ran out of memory, retrying batch \\n {e}\")\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da5807e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2).fit(all_models[0])\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 12))\n",
    "plt.subplots_adjust(right=0.90)  # Оставляем 15% ширины для легенды\n",
    "\n",
    "# Цвета для activity_type\n",
    "unique_activity_types = list(set(activity_type))\n",
    "colors = sns.husl_palette(len(unique_activity_types))\n",
    "activity_color_map = {\n",
    "    atype: color for atype, color in zip(unique_activity_types, colors)\n",
    "}\n",
    "\n",
    "\n",
    "for averaged_data, activity_t in zip(all_models, all_intervals):\n",
    "    proj = pca.transform(averaged_data)\n",
    "    col = [activity_color_map[atype] for atype in activity_t]\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(True, which=\"minor\", linestyle=\":\", linewidth=0.9, color=\"gray\", alpha=0.5)\n",
    "    ax.grid(True, which=\"major\", linestyle=\"-\", linewidth=0.5, color=\"gray\", alpha=0.7)\n",
    "    ax.scatter(proj[:, 0], proj[:, 1], color=col, s=10, edgecolor=\"k\", alpha=0.5)\n",
    "\n",
    "\n",
    "# Создаем легенду с элементами для всех типов активности\n",
    "handles = [\n",
    "    plt.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"o\",\n",
    "        color=\"w\",\n",
    "        label=atype,\n",
    "        markerfacecolor=color,\n",
    "        markersize=10,\n",
    "    )\n",
    "    for atype, color in activity_color_map.items()\n",
    "]\n",
    "\n",
    "# Проверяем, что handles не пустой\n",
    "if handles:\n",
    "    fig.legend(\n",
    "        handles=handles,\n",
    "        title=\"Activity Type\",\n",
    "        loc=\"center left\",  # Привязываем к левому краю области для легенды\n",
    "        bbox_to_anchor=(0.90, 0.5),  # Центрируем вертикально\n",
    "        borderaxespad=0.0,  # Убираем лишние отступы\n",
    "        frameon=False,  # Убираем рамку вокруг легенды\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f4eab827",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2).fit(all_models[0])\n",
    "fig, axs = plt.subplots(5, 5, figsize=(12, 12))\n",
    "plt.subplots_adjust(right=0.90)  # Оставляем 15% ширины для легенды\n",
    "\n",
    "# Цвета для activity_type\n",
    "unique_activity_types = list(set(activity_type))\n",
    "colors = sns.husl_palette(len(unique_activity_types))\n",
    "activity_color_map = {\n",
    "    atype: color for atype, color in zip(unique_activity_types, colors)\n",
    "}\n",
    "\n",
    "act_alignment = {}\n",
    "\n",
    "for ax, atype in zip(axs.flatten(), unique_activity_types):\n",
    "    ax.set_title(atype)\n",
    "    ax.set_xlim(-23, 20)\n",
    "    ax.set_ylim(-22, 19)\n",
    "\n",
    "    ax.minorticks_on()\n",
    "    ax.grid(True, which=\"minor\", linestyle=\":\", linewidth=0.9, color=\"gray\", alpha=0.5)\n",
    "    ax.grid(True, which=\"major\", linestyle=\"-\", linewidth=0.5, color=\"gray\", alpha=0.7)\n",
    "\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    ax.spines[\"bottom\"].set_visible(False)\n",
    "    ax.spines[\"left\"].set_visible(False)\n",
    "\n",
    "    ax.tick_params(axis=\"both\", which=\"both\", length=0)\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "    act_alignment[atype] = ax\n",
    "\n",
    "points_by_activity = {atype: [] for atype in unique_activity_types}\n",
    "for averaged_data, activity_t in zip(all_models, all_intervals):\n",
    "    proj = pca.transform(averaged_data)\n",
    "    for point, atype in zip(proj, activity_t):\n",
    "        points_by_activity[atype].append(point)\n",
    "\n",
    "for atype, ax in act_alignment.items():\n",
    "    pts = np.array(points_by_activity[atype])\n",
    "    if pts.size > 0:\n",
    "        ax.scatter(\n",
    "            pts[:, 0],\n",
    "            pts[:, 1],\n",
    "            s=10,\n",
    "            color=activity_color_map[atype],\n",
    "            edgecolor=\"k\",\n",
    "            alpha=0.25,\n",
    "        )\n",
    "\n",
    "# Создаем легенду с элементами для всех типов активности\n",
    "handles = [\n",
    "    plt.Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"o\",\n",
    "        color=\"w\",\n",
    "        label=atype,\n",
    "        markerfacecolor=color,\n",
    "        markersize=10,\n",
    "    )\n",
    "    for atype, color in activity_color_map.items()\n",
    "]\n",
    "\n",
    "# Проверяем, что handles не пустой\n",
    "if handles:\n",
    "    fig.legend(\n",
    "        handles=handles,\n",
    "        title=\"Activity Type\",\n",
    "        loc=\"center left\",  # Привязываем к левому краю области для легенды\n",
    "        bbox_to_anchor=(0.90, 0.5),  # Центрируем вертикально\n",
    "        borderaxespad=0.0,  # Убираем лишние отступы\n",
    "        frameon=False,  # Убираем рамку вокруг легенды\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
