{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import traceback\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(\"..\"))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import zarr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.base import clone\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import time\n",
    "\n",
    "def create_save_dir(base_path: str, folder_name: str) -> str:\n",
    "    \"\"\"Создаёт директорию с именем, основанным на названии эксперимента,текущей дате и времени.\"\"\"\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "    save_dir = os.path.join(base_path, f\"{folder_name} on {timestamp}\")\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    return save_dir\n",
    "\n",
    "def fit_predict(zarrnik, channel, trial_names, model, labelencoder):\n",
    "    # Используем только лейблы из трейна\n",
    "    X, y = {}, {}\n",
    "    for key, value in trial_names.items():\n",
    "        X[key] = np.concatenate(\n",
    "            [zarrnik[n][\"embedding\"][channel] for n in value], axis=0\n",
    "        )\n",
    "        y[key] = np.concatenate(\n",
    "            [zarrnik[n][\"labels\"] for n in value], axis=0\n",
    "        )\n",
    "\n",
    "    # Обучение модели\n",
    "    model.fit(X[\"train\"], labelencoder.transform(y[\"train\"][:, 1]))\n",
    "\n",
    "    y_hat = model.predict(X[\"test\"])\n",
    "\n",
    "    return labelencoder.transform(y[\"test\"][:, 1]), y_hat #true, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zarr_log_selector(zarrnik):\n",
    "    \"\"\"\n",
    "    Gets Zarr writable group to create logger selector\n",
    "\n",
    "    Input:\n",
    "    - zarrnik: zarr.open_group(...) instance\n",
    "    Output:\n",
    "    - selector: dictionary of funtions depending of type of data\n",
    "    Legit type strings: \"number\", \"string\"\n",
    "\n",
    "    Usage:\n",
    "        zarr_log_selector[str_type](name, data)\n",
    "    \"\"\"\n",
    "    def number_array(name, data):\n",
    "        zarrnik.create_dataset(\n",
    "                name,\n",
    "                data=data,\n",
    "                compressor=zarr.Blosc(cname=\"zstd\", clevel=5),\n",
    "                overwrite=True,\n",
    "            )\n",
    "    def string_array(name, data):\n",
    "        zarrnik.create_dataset(\n",
    "                name,\n",
    "                data=data,\n",
    "                dtype=object, \n",
    "                object_codec=JSON(),\n",
    "                compressor=zarr.Blosc(cname=\"zstd\", clevel=5),\n",
    "                overwrite=True,\n",
    "            )\n",
    "    selector = {\"number\": number_array, \"string\": string_array}\n",
    "    return selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "import numpy as np\n",
    "from numcodecs import Blosc, JSON\n",
    "import json\n",
    "\n",
    "def get_model_string(model_name, params):\n",
    "    return f\"{model_name}|{json.dumps(params, sort_keys=True)}\"\n",
    "\n",
    "def get_index(mapping, key):\n",
    "    \"\"\"Get index in mapping, add if not present.\"\"\"\n",
    "    if key not in mapping:\n",
    "        mapping[key] = len(mapping)\n",
    "    return mapping[key]\n",
    "\n",
    "class ZarrLogWriter:\n",
    "    def __init__(self, zarr_path, n_folds=5):\n",
    "        self.zarr_path = zarr_path\n",
    "        self.n_folds = n_folds\n",
    "        self.store = zarr.open_group(zarr_path, mode='a')\n",
    "        self._init_arrays()\n",
    "        self.sub_chan_map = {}  # \"sub-R1001P_ch0\" -> row index\n",
    "        self.model_map = {}     # \"SVC|{...}\" -> col index\n",
    "\n",
    "    def _init_arrays(self):\n",
    "        compressor = Blosc(cname=\"zstd\", clevel=5)\n",
    "\n",
    "        self.interfold = self.store.require_group(\"interfold\")\n",
    "        self.final = self.store.require_group(\"final\")\n",
    "        self.code = self.store.require_group(\"code\")\n",
    "\n",
    "        if \"metrics\" not in self.code:\n",
    "            self.code.create_dataset(\"metrics\", data=[\"accuracy\", \"precision\", \"recall\", \"f1\", \"time\"],\n",
    "                                    dtype=object, object_codec=JSON())\n",
    "\n",
    "        self.interfold.create_dataset(\"metrics\", shape=(0, 0, self.n_folds, 5), chunks=(1, 1, self.n_folds, 5),\n",
    "                                    dtype=\"float32\", compressor=compressor, overwrite=True)\n",
    "\n",
    "        self.final.create_dataset(\"metrics\", shape=(0, 0, 5), chunks=(1, 1, 5),\n",
    "                                dtype=\"float32\", compressor=compressor, overwrite=True)\n",
    "\n",
    "        self.code.create_dataset(\"sub_chan\", shape=(0,), chunks=(1,), dtype=object,\n",
    "                                object_codec=JSON(), compressor=compressor, overwrite=True)\n",
    "\n",
    "        self.code.create_dataset(\"model_plus_params\", shape=(0,), chunks=(1,), dtype=object,\n",
    "                                object_codec=JSON(), compressor=compressor, overwrite=True)\n",
    "\n",
    "    def _resize_if_needed(self, row, col):\n",
    "        interfold = self.interfold[\"metrics\"]\n",
    "        final = self.final[\"metrics\"]\n",
    "\n",
    "        if row >= interfold.shape[0]:\n",
    "            interfold.resize((row + 1, interfold.shape[1], interfold.shape[2], interfold.shape[3]))\n",
    "            final.resize((row + 1, final.shape[1], final.shape[2]))\n",
    "            self.code[\"sub_chan\"].resize((row + 1,))\n",
    "\n",
    "        if col >= interfold.shape[1]:\n",
    "            interfold.resize((interfold.shape[0], col + 1, interfold.shape[2], interfold.shape[3]))\n",
    "            final.resize((final.shape[0], col + 1, final.shape[2]))\n",
    "            self.code[\"model_plus_params\"].resize((col + 1,))\n",
    "\n",
    "    def log_fold(self, sub, channel, model_name, params, fold_idx, acc, prec, rec, f1, elapsed):\n",
    "        key_row = f\"{sub}_ch{channel}\"\n",
    "        key_col = get_model_string(model_name, params)\n",
    "\n",
    "        row = get_index(self.sub_chan_map, key_row)\n",
    "        col = get_index(self.model_map, key_col)\n",
    "\n",
    "        self._resize_if_needed(row, col)\n",
    "\n",
    "        self.interfold[\"metrics\"][row, col, fold_idx, :] = [acc, prec, rec, f1, elapsed]\n",
    "        self.code[\"sub_chan\"][row] = key_row\n",
    "        self.code[\"model_plus_params\"][col] = key_col\n",
    "\n",
    "    def log_final(self, sub, channel, model_name, params, acc, prec, rec, f1, mean_elapsed):\n",
    "        key_row = f\"{sub}_ch{channel}\"\n",
    "        key_col = get_model_string(model_name, params)\n",
    "\n",
    "        row = get_index(self.sub_chan_map, key_row)\n",
    "        col = get_index(self.model_map, key_col)\n",
    "\n",
    "        self._resize_if_needed(row, col)\n",
    "\n",
    "        self.final[\"metrics\"][row, col, :] = [acc, prec, rec, f1, mean_elapsed]\n",
    "\n",
    "    def flush(self):\n",
    "        # В данном случае ничего не требуется — все изменения сохраняются итеративно.\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_files = \"/trinity/home/asma.benachour/processed_files/\"\n",
    "pdf_output_dir = \"/trinity/home/asma.benachour/PDF/\"\n",
    "subs = [\n",
    "    \"sub-R1001P\",\n",
    "    \"sub-R1002P\",\n",
    "    \"sub-R1003P\",\n",
    "    \"sub-R1010J\",\n",
    "    # \"sub-R1015J\", 4 trials - too small experiment itself\n",
    "    \"sub-R1020J\",\n",
    "    \"sub-R1026D\",\n",
    "    \"sub-R1031M\",\n",
    "    \"sub-R1032D\",\n",
    "    \"sub-R1035M\",\n",
    "]\n",
    "# Создание KFold с перемешиванием\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "channel = 0\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "labelencoder.fit(['rec', 'not-rec'])\n",
    "# experimentation = input(\"Enter experimentation name without spaces:\")\n",
    "experimentation = \"memory_class\"\n",
    "save_dir = create_save_dir(pdf_output_dir, experimentation)\n",
    "log_path = os.path.join(save_dir, f\"log.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Модели для классификации\n",
    "# classification_models = {\n",
    "    #     \"Logistic regression\": LogisticRegression(C=100, penalty=\"l1\", solver=\"liblinear\", max_iter=5000, class_weight=\"balanced\"),\n",
    "    #     \"KNN with best n_neighbors=5\": KNeighborsClassifier(n_neighbors=5, weights=\"distance\", metric=\"manhattan\"),\n",
    "    #     \"SVC with kernel rbf, C=100\": SVC(kernel=\"rbf\", C=100, gamma=\"auto\", probability=True),\n",
    "    #     \"RandomForest with 300 estimators\": RandomForestClassifier(n_estimators=300, max_depth=15, random_state=42, class_weight=\"balanced\"),\n",
    "    #     \"Decision Tree with max_depth=15\": DecisionTreeClassifier(max_depth=15, min_samples_leaf=5, criterion=\"entropy\", random_state=42),\n",
    "    #     \"AdaBoost with n_estimators=200\": AdaBoostClassifier(n_estimators=200, learning_rate=0.2, estimator=DecisionTreeClassifier(max_depth=1), random_state=42)\n",
    "    # }\n",
    "    # Модели для классификации\n",
    "classification_models = {\n",
    "    \"SVC\": {\n",
    "        \"model\": SVC(probability=True),\n",
    "        \"param_grid\": {\n",
    "            \"C\": [1, 50, 100],\n",
    "            \"gamma\": [\"scale\", \"auto\"],\n",
    "            \"kernel\": [\"rbf\"]\n",
    "        }\n",
    "    },\n",
    "    \"RandomForest\": {\n",
    "        \"model\": RandomForestClassifier(class_weight=\"balanced\", random_state=42),\n",
    "        \"param_grid\": {\n",
    "            \"n_estimators\": [50, 100, 200, 300],\n",
    "            \"max_depth\": [5, 10, 15, 20]\n",
    "        }\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        \"model\": LogisticRegression(solver=\"liblinear\", class_weight=\"balanced\", max_iter=5000),\n",
    "        \"param_grid\": {\n",
    "            \"C\": [1, 50, 100],\n",
    "            \"penalty\": [\"l1\", \"l2\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "labelencoder = LabelEncoder()\n",
    "labelencoder.fit(['rec', 'not-rec'])\n",
    "\n",
    "logger = ZarrLogWriter(f'{save_dir}/evaluation.zarr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sub in subs:\n",
    "    zarrnik = zarr.open(f\"{preprocessed_files}/{sub}/WORD.zarr\", mode=\"r\")\n",
    "    keys = list(zarrnik.group_keys())\n",
    "    # for channel in range(zarrnik[keys[0]][\"embedding\"].shape[0]):\n",
    "    for model_name, model_info in classification_models.items():\n",
    "        model_proto = model_info[\"model\"]\n",
    "        param_grid = model_info.get(\"param_grid\", [{}])  # [{}] if no grid specified\n",
    "        for params in ParameterGrid(param_grid):\n",
    "            model = clone(model_proto).set_params(**params)\n",
    "            y_true_arr = []\n",
    "            y_pred_arr = []\n",
    "            start = time.time()\n",
    "            for fold_idx, (train_ix, test_ix) in enumerate(kf.split(keys)):\n",
    "                try:\n",
    "                    trial_names = {\n",
    "                        \"train\": [keys[i] for i in train_ix],\n",
    "                        \"test\": [keys[i] for i in test_ix],\n",
    "                    }\n",
    "\n",
    "                    y_true, y_pred = fit_predict(zarrnik, channel, trial_names, model, labelencoder)\n",
    "\n",
    "                    end = time.time()\n",
    "                    length = end - start\n",
    "\n",
    "                    y_true_arr.append(y_true)\n",
    "                    y_pred_arr.append(y_pred)\n",
    "\n",
    "                    acc = accuracy_score(y_true, y_pred)\n",
    "                    prec = precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "                    rec = recall_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "                    f1 = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "                    # with open(log_path, \"a\") as f:\n",
    "                    #     f.write(\n",
    "                    #         f\"Patient: {sub}. Channel {channel}. Model name: {model_name}. Params: {params}. Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}, F1: {f1:.3f}. Time: {length:.2f}s\\n\"\n",
    "                    #     )\n",
    "                    logger.log_fold(sub, channel, model_name, params, fold_idx, acc, prec, rec, f1, length)\n",
    "\n",
    "                except Exception as e:\n",
    "                    with open(log_path, \"a\") as f:\n",
    "                        f.write(\n",
    "                            f\"==============================================\\n\"\n",
    "                            f\"Error during CV for {sub}, model={model_name}, params={params}\\n\"\n",
    "                            f\"train_ix={train_ix}\\n\"\n",
    "                            f\"test_ix={test_ix}\\n\"\n",
    "                            f\"Error: {e}\\n\"\n",
    "                            f\"{traceback.format_exc()}\\n\"\n",
    "                            f\"==============================================\\n\"\n",
    "                        )\n",
    "\n",
    "            # Оценка метрик\n",
    "            if len(y_true_arr) == 0 or len(y_pred_arr) == 0:\n",
    "                acc = prec = rec = f1 = 0.0\n",
    "                with open(log_path, \"a\") as f:\n",
    "                    f.write(\n",
    "                        f\"No predictions made for {sub} channel {channel} with {model_name} and params={params}. Returning zeros.\\n\"\n",
    "                    )\n",
    "            else:\n",
    "                y_true_all = np.concatenate(y_true_arr)\n",
    "                y_pred_all = np.concatenate(y_pred_arr)\n",
    "\n",
    "                acc = accuracy_score(y_true_all, y_pred_all)\n",
    "                prec = precision_score(y_true_all, y_pred_all, average=\"macro\", zero_division=0)\n",
    "                rec = recall_score(y_true_all, y_pred_all, average=\"macro\", zero_division=0)\n",
    "                f1 = f1_score(y_true_all, y_pred_all, average=\"macro\", zero_division=0)\n",
    "\n",
    "            # with open(log_path, \"a\") as f:\n",
    "            #     f.write(\n",
    "            #         f\"Final metrics for {sub}, channel {channel}, model={model_name}, params={params}:\\n\"\n",
    "            #         f\"Accuracy: {acc:.3f}, Precision: {prec:.3f}, Recall: {rec:.3f}, F1: {f1:.3f}\\n\\n\"\n",
    "            #     )\n",
    "            length = end - start\n",
    "            logger.log_final(sub, channel, model_name, params, acc, prec, rec, f1, length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_chan</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-R1001P_ch0</td>\n",
       "      <td>SVC|{\"C\": 1, \"gamma\": \"scale\", \"kernel\": \"rbf\"}</td>\n",
       "      <td>0.824150</td>\n",
       "      <td>0.412075</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.451800</td>\n",
       "      <td>329.002777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-R1001P_ch0</td>\n",
       "      <td>SVC|{\"C\": 1, \"gamma\": \"auto\", \"kernel\": \"rbf\"}</td>\n",
       "      <td>0.824150</td>\n",
       "      <td>0.412075</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.451800</td>\n",
       "      <td>329.608551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-R1001P_ch0</td>\n",
       "      <td>SVC|{\"C\": 50, \"gamma\": \"scale\", \"kernel\": \"rbf\"}</td>\n",
       "      <td>0.746848</td>\n",
       "      <td>0.471653</td>\n",
       "      <td>0.481918</td>\n",
       "      <td>0.472647</td>\n",
       "      <td>368.036011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-R1001P_ch0</td>\n",
       "      <td>SVC|{\"C\": 50, \"gamma\": \"auto\", \"kernel\": \"rbf\"}</td>\n",
       "      <td>0.748492</td>\n",
       "      <td>0.480316</td>\n",
       "      <td>0.487208</td>\n",
       "      <td>0.479497</td>\n",
       "      <td>413.843536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-R1001P_ch0</td>\n",
       "      <td>SVC|{\"C\": 100, \"gamma\": \"scale\", \"kernel\": \"rbf\"}</td>\n",
       "      <td>0.741091</td>\n",
       "      <td>0.475937</td>\n",
       "      <td>0.483331</td>\n",
       "      <td>0.476495</td>\n",
       "      <td>458.851624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>sub-R1035M_ch0</td>\n",
       "      <td>LogisticRegression|{\"C\": 1, \"penalty\": \"l2\"}</td>\n",
       "      <td>0.551596</td>\n",
       "      <td>0.512335</td>\n",
       "      <td>0.514455</td>\n",
       "      <td>0.505694</td>\n",
       "      <td>11.162992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>sub-R1035M_ch0</td>\n",
       "      <td>LogisticRegression|{\"C\": 50, \"penalty\": \"l1\"}</td>\n",
       "      <td>0.569270</td>\n",
       "      <td>0.517972</td>\n",
       "      <td>0.520482</td>\n",
       "      <td>0.514840</td>\n",
       "      <td>163.267868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>sub-R1035M_ch0</td>\n",
       "      <td>LogisticRegression|{\"C\": 50, \"penalty\": \"l2\"}</td>\n",
       "      <td>0.588369</td>\n",
       "      <td>0.543527</td>\n",
       "      <td>0.550248</td>\n",
       "      <td>0.540713</td>\n",
       "      <td>15.580540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>sub-R1035M_ch0</td>\n",
       "      <td>LogisticRegression|{\"C\": 100, \"penalty\": \"l1\"}</td>\n",
       "      <td>0.585234</td>\n",
       "      <td>0.536629</td>\n",
       "      <td>0.541920</td>\n",
       "      <td>0.534215</td>\n",
       "      <td>160.201874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>sub-R1035M_ch0</td>\n",
       "      <td>LogisticRegression|{\"C\": 100, \"penalty\": \"l2\"}</td>\n",
       "      <td>0.601197</td>\n",
       "      <td>0.545903</td>\n",
       "      <td>0.551407</td>\n",
       "      <td>0.545400</td>\n",
       "      <td>15.122110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           sub_chan                                              model  \\\n",
       "0    sub-R1001P_ch0    SVC|{\"C\": 1, \"gamma\": \"scale\", \"kernel\": \"rbf\"}   \n",
       "1    sub-R1001P_ch0     SVC|{\"C\": 1, \"gamma\": \"auto\", \"kernel\": \"rbf\"}   \n",
       "2    sub-R1001P_ch0   SVC|{\"C\": 50, \"gamma\": \"scale\", \"kernel\": \"rbf\"}   \n",
       "3    sub-R1001P_ch0    SVC|{\"C\": 50, \"gamma\": \"auto\", \"kernel\": \"rbf\"}   \n",
       "4    sub-R1001P_ch0  SVC|{\"C\": 100, \"gamma\": \"scale\", \"kernel\": \"rbf\"}   \n",
       "..              ...                                                ...   \n",
       "247  sub-R1035M_ch0       LogisticRegression|{\"C\": 1, \"penalty\": \"l2\"}   \n",
       "248  sub-R1035M_ch0      LogisticRegression|{\"C\": 50, \"penalty\": \"l1\"}   \n",
       "249  sub-R1035M_ch0      LogisticRegression|{\"C\": 50, \"penalty\": \"l2\"}   \n",
       "250  sub-R1035M_ch0     LogisticRegression|{\"C\": 100, \"penalty\": \"l1\"}   \n",
       "251  sub-R1035M_ch0     LogisticRegression|{\"C\": 100, \"penalty\": \"l2\"}   \n",
       "\n",
       "     accuracy  precision    recall        f1        time  \n",
       "0    0.824150   0.412075  0.500000  0.451800  329.002777  \n",
       "1    0.824150   0.412075  0.500000  0.451800  329.608551  \n",
       "2    0.746848   0.471653  0.481918  0.472647  368.036011  \n",
       "3    0.748492   0.480316  0.487208  0.479497  413.843536  \n",
       "4    0.741091   0.475937  0.483331  0.476495  458.851624  \n",
       "..        ...        ...       ...       ...         ...  \n",
       "247  0.551596   0.512335  0.514455  0.505694   11.162992  \n",
       "248  0.569270   0.517972  0.520482  0.514840  163.267868  \n",
       "249  0.588369   0.543527  0.550248  0.540713   15.580540  \n",
       "250  0.585234   0.536629  0.541920  0.534215  160.201874  \n",
       "251  0.601197   0.545903  0.551407  0.545400   15.122110  \n",
       "\n",
       "[252 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zarr\n",
    "import pandas as pd\n",
    "\n",
    "z = zarr.open_group(f\"/trinity/home/asma.benachour/PDF/memory_class on 2025-04-04_00:04:37/evaluation.zarr\", mode=\"r\")\n",
    "\n",
    "interfold_metrics = z[\"interfold\"][\"metrics\"][:]\n",
    "final_metrics = z[\"final\"][\"metrics\"][:]\n",
    "sub_chan = z[\"code\"][\"sub_chan\"][:]\n",
    "model_plus_params = z[\"code\"][\"model_plus_params\"][:]\n",
    "metric_names = z[\"code\"][\"metrics\"][:]\n",
    "\n",
    "rows = []\n",
    "for i, sub in enumerate(sub_chan):\n",
    "    for j, model in enumerate(model_plus_params):\n",
    "        metrics = final_metrics[i, j]\n",
    "        if not (metrics == 0).all():  # Пропускаем пустые\n",
    "            row = {\n",
    "                \"sub_chan\": sub,\n",
    "                \"model\": model,\n",
    "                metric_names[0]: metrics[0],\n",
    "                metric_names[1]: metrics[1],\n",
    "                metric_names[2]: metrics[2],\n",
    "                metric_names[3]: metrics[3],\n",
    "                metric_names[4]: metrics[4],\n",
    "            }\n",
    "            rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainbert",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
